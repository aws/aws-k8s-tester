apiVersion: batch/v1
kind: Job
metadata:
  name: bert-inference
spec:
  template:
    spec:
      # affinity:
      #   nodeAffinity:
      #     requiredDuringSchedulingIgnoredDuringExecution:
      #       nodeSelectorTerms:
      #         - matchExpressions:
      #             - key: nvidia.com/gpu.present
      #               operator: Exists
      containers:
        - name: bert-inference
          image: {{.BertInferenceImage}}
          command: ["python", "infer.py"]
          env:
            - name: INFERENCE_MODE
              value: {{.InferenceMode}}
          resources:
            limits:
              nvidia.com/gpu: 1
      restartPolicy: OnFailure