apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  name: multi-node-nccl-test
spec:
  slotsPerWorker: {{.GpuPerNode}}
  runPolicy:
    # it may take a bit for the workers to get ready (the container image is heavy)
    # and we don't want the launcher to reach it's CrashLoopBackoff limit in the meantime
    backoffLimit: 20
    cleanPodPolicy: Running
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        spec:
          restartPolicy: OnFailure
          containers:
          - image: {{.NvidiaTestImage}}
            imagePullPolicy: Always
            name: nccl-test-launcher
            env:
            command:
            - mpirun
            - --allow-run-as-root
            - --tag-output
            - -np
            - "{{.WorkerNodeGpuCount}}"
            - -bind-to
            - none
            - -map-by
            - slot
            - -x
            - PATH
            - -x
            - LD_LIBRARY_PATH
            - -x
            - NCCL_DEBUG=INFO
            - -x
            - NCCL_BUFFSIZE={{.NcclBuffSize}}
            - -x
            - NCCL_P2P_NET_CHUNKSIZE="524288"
            - -x
            - NCCL_TUNER_PLUGIN=/opt/aws-ofi-nccl/install/lib/libnccl-ofi-tuner.so
            - --mca
            - pml
            - ^cm,ucx
            - --mca
            - btl
            - tcp,self
            - --mca
            - btl_tcp_if_exclude
            - lo,docker0,veth_def_agent
            - /opt/nccl-tests/build/all_reduce_perf
            - -b
            - "8"
            - -e
            - {{.MaxBytes}}
            - -f
            - "2"
            - -c
            - "1"
            - -n
            - "10"
    Worker:
      replicas: {{.WorkerNodeCount}}
      template:
        spec:
          volumes:
          - name: dshm
            emptyDir:
              medium: Memory
          containers:
          - image: {{.NvidiaTestImage}}
            imagePullPolicy: Always
            name: nccl-test-worker
            volumeMounts:
            - mountPath: /dev/shm
              name: dshm
            resources:
              requests:
                nvidia.com/gpu: {{.GpuPerNode}}
                vpc.amazonaws.com/efa: {{.EfaInterfacePerNode}}
              limits:
                nvidia.com/gpu: {{.GpuPerNode}}
                vpc.amazonaws.com/efa: {{.EfaInterfacePerNode}}
